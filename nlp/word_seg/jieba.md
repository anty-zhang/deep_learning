[[TOC]]

# jieba分词

python中对英文文本预处理用nltk; 中文文本用jieba.

## 分词原理: 基于规则和统计

- 基于规则

基于规则是指根据一个已有的词典，采用前向最大匹配、后向最大匹配、双向最大匹配等人工设定的规则来进行分词。

- 基于统计

基于统计是从大量人工标注语料中总结词的概率分布以及词之间的常用搭配，使用有监督学习训练分词模型。

## 分词的三种模式

```python
# 模式一: 全模式. 把句子中所有可以成词的词语都扫描出来, 速度非常快，但是不能解决歧义
# '我/来到/北京/清华/清华大学/华大/大学'
'/'.join(jieba.cut("我来到北京清华大学", cut_all=True))

# 模式二: 精确模式. 试图将句子最精确地切开，适合文本分析
# '我/来到/北京/清华大学'
'/'.join(jieba.cut("我来到北京清华大学", cut_all=False))

# 模式三: 搜索引擎模式：在精确模式的基础上，对长词再次切分，提高召回率，适合用于搜索引擎分词
# '我/来到/北京/清华/华大/大学/清华大学'
'/'.join(jieba.cut_for_search("我来到北京清华大学"))
```

## 词典/停用词

jieba.load_userdict

## 其它应用

### TF-IDF 关键词提取

```python
import jieba.analyse
content = u'中国特色社会主义是我们党领导的伟大事业，全面推进党的建设新的伟大工程，是这一伟大事业取得胜利的关键所在。党坚强有力，事业才能兴旺发达，国家才能繁荣稳定，人民才能幸福安康。党的十八大以来，我们党坚持党要管党、从严治党，凝心聚力、直击积弊、扶正祛邪，党的建设开创新局面，党风政风呈现新气象。习近平总书记围绕从严管党治党提出一系列新的重要思想，为全面推进党的建设新的伟大工程进一步指明了方向。'

# 第一个参数：待提取关键词的文本
# 第二个参数：返回关键词的数量，重要性从高到低排序
# 第三个参数：是否同时返回每个关键词的权重
# 第四个参数：词性过滤，为空表示不过滤，若提供则仅返回符合词性要求的关键词
keywords = jieba.analyse.extract_tags(content, topK=20, withWeight=True, allowPOS=())

# output
[('党的建设', 0.47331204260459014),
 ('管党', 0.3919595902590164),
 ('伟大工程', 0.3771404058754098),
 ('伟大事业', 0.3669713918327869),
 ('才能', 0.26339384065180327),
 ('治党', 0.22787996150819673),
 ('党要', 0.1959797951295082),
 ('从严治党', 0.1959797951295082),
 ('凝心', 0.1959797951295082),
 ('聚力', 0.1959797951295082),
 ('直击', 0.1959797951295082),
 ('坚强有力', 0.19013266490163933),
 ('扶正祛邪', 0.19013266490163933),
 ('推进', 0.18810840444327867),
 ('政风', 0.18583161138524593),
 ('全面', 0.18439437791967214),
 ('党风', 0.17961047004590164),
 ('新气象', 0.17267839052459016),
 ('兴旺发达', 0.16782157386557378),
 ('习近平', 0.1624867804165574)]
```

### TextRank 关键词提取

```python
import jieba.analyse
content = u'中国特色社会主义是我们党领导的伟大事业，全面推进党的建设新的伟大工程，是这一伟大事业取得胜利的关键所在。党坚强有力，事业才能兴旺发达，国家才能繁荣稳定，人民才能幸福安康。党的十八大以来，我们党坚持党要管党、从严治党，凝心聚力、直击积弊、扶正祛邪，党的建设开创新局面，党风政风呈现新气象。习近平总书记围绕从严管党治党提出一系列新的重要思想，为全面推进党的建设新的伟大工程进一步指明了方向。'

# 第一个参数：待提取关键词的文本
# 第二个参数：返回关键词的数量，重要性从高到低排序
# 第三个参数：是否同时返回每个关键词的权重
# 第四个参数：allowPOS默认为('ns', 'n', 'vn', 'v') 即仅提取地名、名词、动名词、动词
keywords = jieba.analyse.textrank(content, topK=20, withWeight=True, allowPOS=('ns', 'n', 'vn', 'v'))

# output
[('才能', 1.0),
 ('管党', 0.7999933934163805),
 ('全面', 0.7325692441985737),
 ('社会主义', 0.6327916888315029),
 ('围绕', 0.60594603358887),
 ('总书记', 0.5945625023471114),
 ('凝心', 0.5840883789052874),
 ('政风', 0.5792034335473362),
 ('新气象', 0.5772168490112909),
 ('党风', 0.5728262292165519),
 ('呈现', 0.5700456186486299),
 ('推进', 0.5548361394986431),
 ('方向', 0.5150324602730256),
 ('指明', 0.5113586590717408),
 ('治党', 0.5062232626208965),
 ('局面', 0.4744549207999055),
 ('聚力', 0.46596165707522896),
 ('积弊', 0.4646149902996275),
 ('直击', 0.46314922535402286),
 ('国家', 0.46179235227324805)]
```

### 词性标注

```python
import jieba.posseg as pseg
for w in pseg.cut("我爱北京天安门"):
    print(w)

# output
我/r
爱/v
北京/ns
天安门/ns
```

# reference

[fxsjy/jieba](https://github.com/fxsjy/jieba)
